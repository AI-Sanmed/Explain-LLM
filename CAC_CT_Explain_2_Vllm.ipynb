{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a1879-a266-4efb-b848-28a8d40c0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import SamplingParams, AsyncEngineArgs, AsyncLLMEngine\n",
    "from typing import List, Dict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1b5bf-bb3e-410c-b949-9b8ab4ff0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "#%%\n",
    "MODEL_PATH = os.environ.get('MODEL_PATH', '/data/zhenyu/LLM_Model/GLM_4/GLM4_Chat/')\n",
    "max_length = 512\n",
    "top_p = 1\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef35022-941b-4bd7-8b4c-18bfe3844edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_dir: str):\n",
    "    engine_args = AsyncEngineArgs(\n",
    "        model=model_dir,\n",
    "        tokenizer=model_dir,\n",
    "        tensor_parallel_size=1,\n",
    "        dtype=\"bfloat16\",\n",
    "        trust_remote_code=True,\n",
    "        gpu_memory_utilization=1,\n",
    "        enforce_eager=True,\n",
    "        worker_use_ray=True,\n",
    "        engine_use_ray=False,\n",
    "        disable_log_requests=True\n",
    "        # 如果遇见 OOM 现象，建议开启下述参数\n",
    "        # enable_chunked_prefill=True,\n",
    "        # max_num_batched_tokens=8192\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_dir,\n",
    "        trust_remote_code=True,\n",
    "        encode_special_tokens=True\n",
    "    )\n",
    "    engine = AsyncLLMEngine.from_engine_args(engine_args)\n",
    "    return engine, tokenizer\n",
    "\n",
    "async def vllm_gen(messages: List[Dict[str, str]], top_p: float, temperature: float, max_dec_len: int):\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=False\n",
    "    )\n",
    "    params_dict = {\n",
    "        \"n\": 1,\n",
    "        \"best_of\": 1,\n",
    "        \"presence_penalty\": 1.0,\n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": -1,\n",
    "        \"use_beam_search\": False,\n",
    "        \"length_penalty\": 1,\n",
    "        \"early_stopping\": False,\n",
    "        \"stop_token_ids\": [151329, 151336, 151338],\n",
    "        \"ignore_eos\": False,\n",
    "        \"max_tokens\": max_dec_len,\n",
    "        \"logprobs\": None,\n",
    "        \"prompt_logprobs\": None,\n",
    "        \"skip_special_tokens\": True,\n",
    "    }\n",
    "    sampling_params = SamplingParams(**params_dict)\n",
    "    async for output in engine.generate(inputs=inputs, sampling_params=sampling_params, request_id=f\"{time.time()}\"):\n",
    "        yield output.outputs[0].text\n",
    "\n",
    "def perdict(messages):\n",
    "    current_length = 0\n",
    "    output = \"\"\n",
    "    for output in vllm_gen(messages, top_p, temperature, max_length):\n",
    "        print(output[current_length:], end=\"\", flush=True)\n",
    "        current_length = len(output)\n",
    "    return output\n",
    "\n",
    "engine, tokenizer = load_model_and_tokenizer(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd741d-c0e6-4246-a232-258122745f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_1 = f\"\"\"\n",
    "你是一个圣美生物有限公司一名经验丰富的呼吸科医生。患者已经做过了CAC（循环染色体异常细胞检测）与CTAI（肺部CT扫描与肺结节风险评估）检测。\n",
    "请先根据患者提供的CAC检测报告与CTAI检测报告，综合两份检测报告和以下参考信息，对每个结节进行分析解读。\n",
    "最后给出整体建议。【注意，不要使用肯定词汇，例如：立即，必须，应该等词汇。应考虑结节大小给出随访或积极治疗建议。】\n",
    "```参考信息：\n",
    "CAC:\n",
    "    CAC > 9：高风险区间；\n",
    "    3 ≤ CAC ≤ 9: 中高风险区间；\n",
    "    CAC < 3: 低风险区间；\n",
    "结节风险预测：\n",
    "    结节风险预测 > 85%: 高风险结节；\n",
    "    65% < 结节风险预测 < 85%: 中高风险结节；\n",
    "    40% < 结节风险预测 < 65%: 中风险结节；\n",
    "    结节风险预测 < 40%: 低风险结节；\n",
    "    \n",
    "CAC > 9, CTAI 结节风险 > 85%：分析解读参考 “ CAC、CTAI均在高风险区间，应选择积极治疗，特别是结节大小≥8mm，手术干预指征更强。如果结节＜8mm，或患者拒绝手术治疗时，可选择密切观察（每3个月复查胸部CT），随访过程中如有结节增大、密度增高、实性成分增加等，需再次建议患者积极治疗（手术切除）。当然，尽管CAC大于9，CTAI＞85%，提示肺结节恶性风险高危，但手术切除后病理依然存在良性结节的可能，虽然这种可能性比较小”。\n",
    "CAC > 9, CTAI 结节风险 < 85%：分析解读参考 “ CAC高风险区间，CTAI未达高风险区间，建议抗炎治疗（两周）后3个月复查胸部CT，同时进行CTAI随访对比。如有结节增大、密度增高、实性成分增加等，可建议积极治疗，如果没有结节增大、密度增高、实性成分增加等，应对患者进行密切随访，每3个月复查胸部CT，连续3-4次，随访观察过程中出现结节恶性倾向增大（结节增大、密度增高、实性成分增加或出现下列征象一项以上时：结节分叶、毛刺、胸膜牵拉、血管集束、空泡征等，建议积极治疗。”\n",
    "```\n",
    "\"\"\"\n",
    "messages_1 = []\n",
    "messages_1.append({\"role\":\"system\", \"content\":system_prompt_1})\n",
    "check_info_1 = \"\"\"\n",
    "患者姓名：尹玉梅；\n",
    "CAC: 20;\n",
    "结节信息: \n",
    "1号结节 结节风险预测：90%；结节类型：混合型；结节大小：15mm, \n",
    "2号结节 结节风险预测：80%；结节类型：磨玻璃型；结节大小：6mm；\n",
    "\"\"\"\n",
    "messages_1.append({\"role\":\"user\", \"content\":check_info_1})\n",
    "import time\n",
    "start_time = time.time()\n",
    "current_length = 0\n",
    "output = \"\"\n",
    "async for output in vllm_gen(messages_1, top_p, temperature, max_length):\n",
    "    print(output[current_length:], end=\"\", flush=True)\n",
    "    current_length = len(output)\n",
    "end_time = time.time()\n",
    "print('Use Time: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff07dc-5b7f-43ee-b41b-e466d7e6cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55089c48-9a31-4efa-afa9-9c50a971473e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "llama_factory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
