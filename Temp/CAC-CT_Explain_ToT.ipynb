{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a997ffad-a414-455a-a86a-5fdf809ef3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from threading import Thread\n",
    "from transformers import AutoTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer, AutoModel\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f2d92c-39ef-4710-bc6e-104d2c941907",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.environ.get('MODEL_PATH', '/data/zhenyu/LLM_Model/GLM_4/GLM4_Chat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048e531-aaf3-4856-99de-533072f808f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    trust_remote_code=True,\n",
    "    encode_special_tokens=True\n",
    ")\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\", # Use Flash Attention\n",
    "    # torch_dtype=torch.bfloat16, #using flash-attn must use bfloat16 or float16\n",
    "    device_map=\"auto\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49270d-20cb-4674-99c5-8fef2b0b106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        stop_ids = model.config.eos_token_id\n",
    "        for stop_id in stop_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def predict(messages):\n",
    "    stop = StopOnTokens()\n",
    "    model_inputs = tokenizer.apply_chat_template(messages,\n",
    "                                                 add_generation_prompt=True,\n",
    "                                                 tokenize=True,\n",
    "                                                 return_tensors=\"pt\").to(next(model.parameters()).device)\n",
    "    streamer = TextIteratorStreamer(tokenizer, timeout=60, skip_prompt=True, skip_special_tokens=True)\n",
    "    generate_kwargs = {\n",
    "        \"input_ids\": model_inputs,\n",
    "        \"streamer\": streamer,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"do_sample\": False,\n",
    "        \"top_p\": 1,\n",
    "        \"temperature\": 0.5,\n",
    "        \"stopping_criteria\": StoppingCriteriaList([stop]),\n",
    "        \"repetition_penalty\": 1,\n",
    "        \"eos_token_id\": model.config.eos_token_id,\n",
    "    }\n",
    "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
    "    t.start()\n",
    "    result = ''\n",
    "    for new_token in streamer:\n",
    "        result += new_token\n",
    "        print(new_token, end='')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ee418-fa91-4e68-88ba-b49e0dffe5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tot_prompt(cac_value, ctai_value, nodule_size):\n",
    "    return f\"\"\"\n",
    "#肺结节风险评估\n",
    "\n",
    "## 1. 初始化\n",
    "\n",
    "请根据以下信息评估肺结节风险并给出建议：\n",
    "- CAC值: {cac_value}\n",
    "- CTAI值: {ctai_value}\n",
    "- 结节大小: {nodule_size} mm\n",
    "\n",
    "## 2. 风险评估\n",
    "\n",
    "请按以下步骤进行思考：\n",
    "\n",
    "1. 评估CAC值\n",
    "    如果CAC > 9，考虑高风险\n",
    "    如果3 ≤ CAC ≤ 9，考虑中高风险\n",
    "    如果CAC < 3，考虑低风险\n",
    "2. 评估CTAI值\n",
    "    如果CTAI > 85%，考虑高风险\n",
    "    如果65% ≤ CTAI ≤ 85%，考虑中高风险\n",
    "    如果CTAI < 65%，考虑低风险\n",
    "3. 综合CAC和CTAI\n",
    "    如果两者都高，风险最高\n",
    "    如果一高一低，需要进一步考虑\n",
    "    如果两者都低，风险相对较低\n",
    "4. 考虑结节大小\n",
    "    如果大小 ≥ 8mm，增加风险\n",
    "    如果大小 < 8mm，相对风险较低\n",
    "\n",
    "## 3. 建议生成\n",
    "\n",
    "基于以上评估，请给出具体建议：\n",
    "\n",
    "1. 治疗方案\n",
    "    是否建议积极治疗（如手术）？\n",
    "    是否建议密切随访？\n",
    "    是否建议常规体检？\n",
    "2. 随访计划\n",
    "    建议多长时间进行一次复查？\n",
    "    每次复查应包括哪些检查项目？\n",
    "3. 其他注意事项\n",
    "    是否需要考虑患者的其他个人因素？\n",
    "    是否有其他需要患者注意的事项？\n",
    "\n",
    "## 4. 总结\n",
    "\n",
    "请总结你的评估过程和最终建议，确保逻辑清晰，建议具体可行。\n",
    "\n",
    "请以JSON格式输出你的结果，包括以下字段：\n",
    "\"risk_level\": \"高/中高/中/中低/低\",\n",
    "\"treatment_plan\": \"建议的治疗方案\",\n",
    "\"follow_up_plan\": \"建议的随访计划\",\n",
    "\"additional_notes\": \"其他注意事项\",\n",
    "\"summary\": \"总结\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5adf2-47c0-46f7-a24b-cd74ab3c8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_tot_prompt(10, '90%', 15)\n",
    "messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a medical AI assistant specialized in lung nodule risk assessment.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "predict(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414dab1-0c00-420f-8b96-f46d894017e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tot_prompt_2(CAC_VALUE, CTAI_VALUE,NODULE_SIZE, NODULE_CHANGE):\n",
    "    return f\"\"\"\n",
    "1. 初始化\n",
    "请根据以下信息评估肺结节风险并给出建议：\n",
    "\n",
    "CAC值: {CAC_VALUE}\n",
    "CTAI值: {CTAI_VALUE}\n",
    "结节大小: {NODULE_SIZE} mm\n",
    "结节变化: {NODULE_CHANGE}\n",
    "\n",
    "2. 风险评估\n",
    "请按以下步骤进行思考，并在每一步详细解释您的推理过程：\n",
    "\n",
    "评估CAC值:\n",
    "\n",
    "CAC > 9: 高风险\n",
    "3 ≤ CAC ≤ 9: 中高风险\n",
    "CAC < 3: 低风险\n",
    "\n",
    "\n",
    "评估CTAI值:\n",
    "\n",
    "CTAI > 85%: 高风险\n",
    "65% ≤ CTAI ≤ 85%: 中高风险\n",
    "CTAI < 65%: 低风险\n",
    "\n",
    "\n",
    "综合CAC和CTAI:\n",
    "\n",
    "如果CAC > 9且CTAI > 85%，判定为最高风险\n",
    "如果CAC > 9但CTAI < 85%，或3 ≤ CAC ≤ 9且CTAI > 85%，判定为高风险\n",
    "其他情况需要进一步考虑结节大小和其他因素\n",
    "\n",
    "\n",
    "考虑结节大小:\n",
    "\n",
    "结节大小 ≥ 8mm: 显著增加风险\n",
    "结节大小 < 8mm: 相对风险较低\n",
    "结节大小 > 15mm: 即使其他指标较低也需要特别关注\n",
    "\n",
    "考虑结节变化：\n",
    "结节增大：考虑恶性病变，感染或炎症\n",
    "结节变小：考虑良性病变\n",
    "无明显变化：稳定的良性变化\n",
    "\n",
    "\n",
    "\n",
    "3. 建议生成\n",
    "基于以上评估，请给出具体建议，并解释每个建议的理由：\n",
    "\n",
    "治疗方案:\n",
    "\n",
    "是否建议积极治疗（如手术）？在什么条件下建议手术？\n",
    "是否建议抗炎治疗？抗炎治疗多久后复查？\n",
    "是否建议密切随访？频率如何？\n",
    "是否建议常规体检？频率如何？\n",
    "\n",
    "\n",
    "随访计划:\n",
    "\n",
    "建议多长时间进行一次复查？为什么？\n",
    "每次复查应包括哪些检查项目？为什么需要这些项目？\n",
    "\n",
    "\n",
    "其他注意事项:\n",
    "\n",
    "有哪些生活方式的建议？\n",
    "患者需要注意哪些可能的症状变化？\n",
    "\n",
    "\n",
    "\n",
    "4. 特殊情况考虑\n",
    "请考虑以下特殊情况，并给出相应的建议：\n",
    "\n",
    "如果患者拒绝手术，替代方案是什么？\n",
    "如果结节在随访中发现变化（如大小增加、密度增高），应如何处理？\n",
    "对于年龄较大或有其他健康问题的患者，评估标准是否需要调整？\n",
    "\n",
    "5. 总结\n",
    "请总结您的评估过程和最终建议，确保逻辑清晰，建议具体可行。包括：\n",
    "\n",
    "总体风险评估\n",
    "主要建议及其理由\n",
    "需要进一步关注或澄清的问题\n",
    "\n",
    "请以JSON格式输出您的结果，包括以下字段：\n",
    "\"risk_level\": \"高/中/低\",\n",
    "\"cac_assessment\": \"CAC值评估结果\",\n",
    "\"ctai_assessment\": \"CTAI值评估结果\",\n",
    "\"nodule_size_assessment\": \"结节大小评估结果\",\n",
    "\"overall_risk_assessment\": \"综合风险评估结果\",|\n",
    "\"treatment_plan\": \"建议的治疗方案\",\n",
    "\"follow_up_plan\": \"建议的随访计划\",\n",
    "\"additional_notes\": \"其他注意事项\",\n",
    "\"special_considerations\": \"特殊情况的考虑\",\n",
    "\"summary\": \"总结\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4570aa7-fb85-4e1d-a83c-eca346aebe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = create_tot_prompt_2(9, '30%', 9,\"较前增大\")\n",
    "system_prompt = f\"\"\"\n",
    "您是一位专门从事肺结节风险评估的AI医疗助手。您的知识基于最新的医学研究和指南。在评估过程中，请严格遵循以下原则：\n",
    "\n",
    "1.使用CAC（Circulating genetically Abnormal Cell）和CTAI（Lung Nodule risk values from CTAI）作为主要评估指标。\n",
    "2.考虑结节大小作为额外的风险因素。\n",
    "3.提供基于证据的建议，并明确说明建议的依据。\n",
    "4.在不确定的情况下，建议进一步检查或咨询专科医生。\n",
    "5.所有建议都应考虑患者安全为首要原则。\n",
    "\"\"\"\n",
    "messages_2 = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt2}\n",
    "]\n",
    "predict(messages_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345aee7c-b69a-43fe-9d5e-b5be63e09f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
